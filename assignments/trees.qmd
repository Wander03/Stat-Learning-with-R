---
title: "Lab 4: Decision Trees"
author: "Andrew Kerr"
format: 
  html:
    code-fold: false
    code-line-numbers: true
    code-tools: true
    self-contained: true
editor: source
execute:
  message: false
---

## Setup

Declare your libraries:

```{r}
#| label: libraries-r
#| include: false
library(tidyverse)
library(tidymodels)
library(glmnet)
library(discrim)
library(rpart)
library(rpart.plot)
library(baguette)
library(janitor)
library(kableExtra)
```

# Dataset 1: Mushrooms

The first dataset we will study today concerns mushrooms that grow in the wild. An expert mushroom forager can identify the species by its appearance, and determine if the mushroom is edible or poisonous.

Can we train a model to do the same?

Read the data in as follows. (You do need the extra bit of code in the `read_csv` function, make sure you copy it over.)

```{r}
set.seed(123)

mushrooms <- read_csv("https://www.dropbox.com/s/jk5q3dq1u63ey1e/mushrooms.csv?dl=1",
                      col_types = str_c(rep("c", 23), collapse = "")
                      ) 

mushrooms <- mushrooms %>%
  mutate(
    across(.cols = everything(), 
           .fns = ~ as.factor(.x)
           )
    ) %>%
  janitor::clean_names()

mushrooms <- mushrooms %>%
  dplyr::select(-veil_type)
```

You can find further documentation of the dataset here: https://www.kaggle.com/uciml/mushroom-classification

## Part One: A perfect tree

1. Fit a single decision tree to the **full** mushroom data, and plot the resulting tree. You should find that almost all mushrooms are perfectly classified; that is, the resulting leaf nodes are very close to 100% pure.

```{r}
#| label: perfect-tree-fit

tree_mod <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

mroom_recipe <- recipe(class ~ ., 
                     data = mushrooms)

tree_wflow <- workflow() %>%
  add_model(tree_mod) %>% 
  add_recipe(mroom_recipe)

tree_fit <- tree_wflow %>% fit(mushrooms)

tree_fitted <- tree_fit %>% 
  extract_fit_parsnip()

rpart.plot(tree_fitted$fit, roundint = FALSE)
```

2. Based on the tree that results, suggest a "nature guide" that tells people which mushrooms are safe to eat and which aren't.

If the mushroom smells like almond, anise, or nothing and has a buff, black, chocolate, brown, orange, purple, white, or yellow (aka not green) spore print color, then there is a 99.99% chance that it is edible! On the other hand, if it smells like the previously mentioned smells and has a green spore print color or smells creosote, fishy, foul, musty, pungent, or spicy, then it is 100% poisonous!

## Part Two: ... or is it?

Before we send people off into the world to each poisonous mushrooms, we want to be confident of our guidelines. The decision tree in Q1 may achieve perfection on the data it is fit to, but do we believe these guidelines will hold for future data?

Apply each of the following resampling and / or ensemble techniques to this classification problem. For each, you should either argue that

(a) The classification rules we learned in Part One probably apply to all mushrooms; or

(b) The classification rules we learned in Part One are overfit to this particular sample of mushrooms and / or set of predictors.

3. Cross-validation

```{r}
#| label: CV-mushroom

mroom_cvs <- vfold_cv(mushrooms, v = 10)

tree_fit_cv <- tree_wflow %>% fit_resamples(mroom_cvs,
                                         metrics = metric_set(accuracy, roc_auc, precision, recall, gain_capture)
                                         )

tree_fit_cv %>% 
  collect_metrics() %>%
  kable()
```

Based on the CV results, the classification results we learned in Part 1 definitely apply to all mushrooms! Yippee, have a feast! Our accuracy is almost perfect, along with our precision, recall, ROC AUC, and gain capture.

4. Bagging

```{r}
#| label: tune-bag

bag_spec <- bag_tree(cost_complexity = tune(), 
                       min_n = tune(),
                       tree_depth = tune()) %>%
  set_engine("rpart", times = 5) %>%
  set_mode("classification")

bag_grid <- grid_regular(cost_complexity(),
                        min_n(),
                        tree_depth(),
                        levels = 3
                        )

bag_tree_wflow_tune <- workflow() %>%
  add_model(bag_spec) %>%
  add_recipe(mroom_recipe)

bag_tree_fit_tune <- bag_tree_wflow_tune %>%
  tune_grid(
    grid = bag_grid,
    resamples = mroom_cvs
    ) 

bag_tree_fit_tune %>% 
  collect_metrics() %>%
  filter(.metric == 'roc_auc') %>%
  slice_max(mean) %>%
  kable()
```

```{r}
#| label: bagging-mushroom

bag_tree_mod <- bag_tree(cost_complexity = 1e-10, 
                         min_n = 2,
                         tree_depth = 8) %>%
  set_engine("rpart", times = 5) %>%
  set_mode("classification")

bag_tree_wflow <- workflow() %>%
  add_recipe(mroom_recipe) %>%
  add_model(bag_tree_mod)

bag_tree_fit <- bag_tree_wflow %>%
  fit(mushrooms)

mushrooms <- mushrooms %>%
  bind_cols(predict(bag_tree_fit, mushrooms, type = "prob")) %>%
  mutate(
    pred_bagging = predict(bag_tree_fit, mushrooms)$.pred_class,
    pred_e_bagging = .pred_e,
    pred_p_bagging = .pred_p
  ) %>%
  select(-.pred_e, -.pred_p)

accuracy_tree_bag <- mushrooms %>%
  accuracy(
    truth = class,
    estimate = pred_bagging
  )

roc_auc_tree_bag <- mushrooms %>%
  roc_auc(
    truth = class,
    pred_e_bagging
    )

gain_capture_tree_bag <- mushrooms %>%
  gain_capture(
    truth = class,
    pred_e_bagging
    )

precision_tree_bag <- mushrooms %>%
  precision(
    truth = class,
    estimate = pred_bagging
  )

recall_tree_bag <- mushrooms %>%
  recall(
    truth = class,
    estimate = pred_bagging
  )

rbind(accuracy_tree_bag, roc_auc_tree_bag, gain_capture_tree_bag, precision_tree_bag, recall_tree_bag) %>%
  kable()
```

Oh wow, we are even better then we were with CV; we are perfect in all metrics! We should, once again, for sure, without a doubt, follow our rules from Part 1. 

5. Random forests

```{r}
#| label: tune-RF

rf_spec <- rand_forest(mtry = tune(), 
                       min_n = tune(),
                       trees = 10) %>%
  set_engine("ranger") %>%
  set_mode("classification")

rf_grid <- grid_regular(mtry(c(1, 15)),
                        min_n(),
                        levels = 5
                        )

rf_tree_wflow_tune <- workflow() %>%
  add_model(rf_spec) %>%
  add_recipe(mroom_recipe)

rf_tree_fit_tune <- rf_tree_wflow_tune %>%
  tune_grid(
    grid = rf_grid,
    resamples = mroom_cvs
    ) 

rf_tree_fit_tune %>% 
  collect_metrics() %>%
  filter(.metric == 'roc_auc') %>%
  slice_max(mean) %>%
  kable()
```

```{r}
#| label: RF-mushroom

rf_mod <- rand_forest(mtry = 4,
                      min_n = 2) %>%
  set_engine("ranger") %>%
  set_mode("classification")

rf_tree_wflow <- workflow() %>%
  add_recipe(mroom_recipe) %>%
  add_model(rf_mod)

rf_tree_fit <- rf_tree_wflow %>%
  fit(mushrooms)

mushrooms <- mushrooms %>%
  bind_cols(predict(rf_tree_fit, mushrooms, type = "prob")) %>%
  mutate(
    pred_rf = predict(rf_tree_fit, mushrooms)$.pred_class,
    pred_e_rf = .pred_e,
    pred_p_rf = .pred_p
  ) %>%
  select(-.pred_e, -.pred_p)

accuracy_tree_rf <- mushrooms %>%
  accuracy(
    truth = class,
    estimate = pred_rf
  )

roc_auc_tree_rf <- mushrooms %>%
  roc_auc(
    truth = class,
    pred_e_rf
    )

gain_capture_tree_rf <- mushrooms %>%
  gain_capture(
    truth = class,
    pred_e_rf
    )

precision_tree_rf <- mushrooms %>%
  precision(
    truth = class,
    estimate = pred_rf
  )

recall_tree_rf <- mushrooms %>%
  recall(
    truth = class,
    estimate = pred_rf
  )

rbind(accuracy_tree_rf, roc_auc_tree_rf, gain_capture_tree_rf, precision_tree_rf, recall_tree_rf) %>%
  kable()
```

Yet again, we are looking solid! It is almost like we are too good at this, hopefully this dataset perfectly represents all mushrooms in the wild so we can follow our guide from Part 1.

# Dataset 2: Telecom Customers

Congratulations! You have been hired by the Data Science division of a major telecommunication company.

The Sales division of the company wants to understand how customer demographics - such as their age, income, marital status, employment status, etc - impact the customers' behavior. They have identified four different types of customers, and labeled a dataset of existing customers with these categories.

```{r}
#| message: false

tele <- read_csv("https://www.dropbox.com/s/9dymy30v394ud8h/Telecust1.csv?dl=1")

tele <- tele %>%
  mutate(
    across(.cols = c(region, marital, address, ed, retire, gender, reside, custcat), 
           .fns = ~ as.factor(.x)
           )
    ) %>%
  janitor::clean_names()

tele %>% 
  ggplot(aes(x = custcat)) +
  geom_bar(fill = 'firebrick') +
  theme_bw() +
  labs(
    x = 'Customer Category',
    y = 'Count',
    title = 'Counts of Customer Categories'
  )
```

Further documentation of this data can be found here: https://www.kaggle.com/prathamtripathi/customersegmentation

You've been tasked with studying the customer demographics and customer categories. The company would like two results from you:

- A model that can be used to predict what category a new customer who signs up will likely fall into.

```{r}
#| label: best-tuning
#| warning: false

tele_cvs <- vfold_cv(tele, v = 10)

tele_recipe <- recipe(custcat ~ ., data = tele)

rf_spec <- rand_forest(mtry = tune(), 
                       min_n = tune(),
                       trees = 10) %>%
  set_engine("ranger", importance = 'impurity') %>%
  set_mode("classification")

rf_grid <- grid_regular(mtry(c(1, 11)),
                        min_n(c(70, 90)),
                        levels = 10
                        )

rf_tree_wflow_tune <- workflow() %>%
  add_model(rf_spec) %>%
  add_recipe(tele_recipe)

rf_tree_fit_tune <- rf_tree_wflow_tune %>%
  tune_grid(
    grid = rf_grid,
    resamples = tele_cvs,
    metrics = metric_set(accuracy, roc_auc, precision, recall, gain_capture)
    ) 

rf_tree_fit_tune %>% 
  collect_metrics() %>%
  filter(.metric == 'gain_capture') %>%
  slice_max(mean, n = 3) %>%
  kable()

rf_tree_fit_tune %>% 
  collect_metrics() %>%
  filter(.metric == 'precision') %>%
  slice_max(mean, n = 3) %>%
  kable()

rf_tree_fit_tune %>% 
  collect_metrics() %>%
  filter(.metric == 'recall') %>%
  slice_max(mean, n = 3) %>%
  kable()

rf_tree_fit_tune %>% 
  collect_metrics() %>%
  filter(.metric == 'roc_auc') %>%
  slice_max(mean, n = 3) %>%
  kable()
```

```{r}
#| label: best-predictions

rf_spec <- rand_forest(mtry = 4, 
                       min_n = 83,
                       trees = 10) %>%
  set_engine("ranger", importance = 'impurity') %>%
  set_mode("classification")

rf_tree_wflow <- workflow() %>%
  add_model(rf_spec) %>%
  add_recipe(tele_recipe)

rf_tree_fit <- rf_tree_wflow %>%
  fit(tele)

tele_metrics <- tele %>%
  bind_cols(predict(rf_tree_fit, tele, type = "prob")) %>%
  mutate(
    pred_rf = predict(rf_tree_fit, tele)$.pred_class,
    pred_a_rf = .pred_A,
    pred_b_rf = .pred_B,
    pred_c_rf = .pred_C,
    pred_d_rf = .pred_D
  ) %>%
  select(-starts_with('.pred_'))

accuracy_tree_rf <- tele_metrics %>%
  accuracy(
    truth = custcat,
    estimate = pred_rf
  )

roc_auc_tree_rf <- tele_metrics %>%
  roc_auc(
    truth = custcat,
    pred_a_rf, pred_b_rf, pred_c_rf, pred_d_rf
    )

gain_capture_tree_rf <- tele_metrics %>%
  gain_capture(
    truth = custcat,
    pred_a_rf, pred_b_rf, pred_c_rf, pred_d_rf
    )

precision_tree_rf <- tele_metrics %>%
  precision(
    truth = custcat,
    estimate = pred_rf
  )

recall_tree_rf <- tele_metrics %>%
  recall(
    truth = custcat,
    estimate = pred_rf
  )

rbind(accuracy_tree_rf, roc_auc_tree_rf, gain_capture_tree_rf, precision_tree_rf, recall_tree_rf) %>%
  kable()
```

- Insight into what demographics are associated with these customer differences.

```{r}
#| label: best-interpretations

rf_tree_fit_extracted <- rf_tree_fit %>%
  extract_fit_parsnip()

ranger_fit <- rf_tree_fit_extracted$fit

importance(ranger_fit) %>%
  data.frame(Feature = names(.), Importance = .) %>%
  ggplot(aes(x = Importance, y = reorder(Feature, -Importance))) +
  geom_col(fill = 'firebrick') +
  theme_bw() +
  labs(
    x = 'Variable Importance',
    y = 'Features',
    title = 'Random Forest Variable Importance'
  )
```

```{r}
#| label: explain-tuning
#| warning: false

tele_cvs_2 <- vfold_cv(tele, v = 10) %>%
  step_rm(address)

tele_recipe_2 <- recipe(custcat ~ ., data = tele) %>%
  step_rm(address)

dc_spec <- decision_tree(cost_complexity = tune(), 
                         tree_depth = tune(),
                         min_n = tune()) %>%
  set_engine("rpart") %>%
  set_mode("classification")

dc_grid <- grid_regular(cost_complexity(),
                        tree_depth(),
                        min_n(),
                        levels = 5
                        )

dc_tree_wflow_tune <- workflow() %>%
  add_model(dc_spec) %>%
  add_recipe(tele_recipe_2)

dc_tree_fit_tune <- dc_tree_wflow_tune %>%
  tune_grid(
    grid = dc_grid,
    resamples = tele_cvs_2,
    metrics = metric_set(accuracy, roc_auc, precision, recall, gain_capture)
    ) 

dc_tree_fit_tune %>% 
  collect_metrics() %>%
  filter(.metric == 'gain_capture') %>%
  slice_max(mean, n = 3) %>%
  kable()

dc_tree_fit_tune %>% 
  collect_metrics() %>%
  filter(.metric == 'precision') %>%
  slice_max(mean, n = 3) %>%
  kable()

dc_tree_fit_tune %>% 
  collect_metrics() %>%
  filter(.metric == 'recall') %>%
  slice_max(mean, n = 3) %>%
  kable()

dc_tree_fit_tune %>% 
  collect_metrics() %>%
  filter(.metric == 'roc_auc') %>%
  slice_max(mean, n = 3) %>%
  kable()
```

```{r}
#| label: best-tree

dc_spec <- decision_tree(cost_complexity = 0, 
                         tree_depth = 4,
                         min_n = 40) %>%
  set_engine("rpart") %>%
  set_mode("classification")

dc_tree_wflow <- workflow() %>%
  add_model(dc_spec) %>%
  add_recipe(tele_recipe_2)

dc_tree_fit <- dc_tree_wflow %>%
  fit(tele)

dc_tree_extracted <- dc_tree_fit %>%
  extract_fit_parsnip()

tele_metrics <- tele_metrics %>%
  bind_cols(predict(dc_tree_fit, tele, type = "prob")) %>%
  mutate(
    pred_dc = predict(dc_tree_fit, tele)$.pred_class,
    pred_a_dc = .pred_A,
    pred_b_dc = .pred_B,
    pred_c_dc = .pred_C,
    pred_d_dc = .pred_D
  ) %>%
  select(-starts_with('.pred_'))

accuracy_tree_dc <- tele_metrics %>%
  accuracy(
    truth = custcat,
    estimate = pred_dc
  )

roc_auc_tree_dc <- tele_metrics %>%
  roc_auc(
    truth = custcat,
    pred_a_dc, pred_b_dc, pred_c_dc, pred_d_dc
    )

gain_capture_tree_dc <- tele_metrics %>%
  gain_capture(
    truth = custcat,
    pred_a_dc, pred_b_dc, pred_c_dc, pred_d_dc
    )

precision_tree_dc <- tele_metrics %>%
  precision(
    truth = custcat,
    estimate = pred_dc
  )

recall_tree_dc <- tele_metrics %>%
  recall(
    truth = custcat,
    estimate = pred_dc
  )

rbind(accuracy_tree_dc, roc_auc_tree_dc, gain_capture_tree_dc, precision_tree_dc, recall_tree_dc) %>%
  kable()

rpart.plot(dc_tree_extracted$fit, roundint = FALSE)
```

We can say that the customers tenure with the company, education group, and average salary are the most important demographics when categorizing a customer with this model.

#### Part Four: Report to your manager

Your manager, the head of the Data Science department, would like a summary of your work. She does not need to see every single detail of every step of your process, but she does need to know a basic outline of what you tried, how you made your decisions, and why you settled on certain choices.

You can assume she has taken Stat 551, and you may use any "lingo" you want; for example, you can reference the Gini Index without having to explain what it is.

Since we want a model that prioritizes correctly classifying customers into the correct category that is also easy to interpret, I decided to go with a decision tree. However, a single decision tree, although straightforwards to interpret, might not provide the best predictions. Therefore, we need to consider a bagged decision tree or a random forest. I tuned a random forest model with 10-fold cross validation, allowing the range of the predictor subset size to including the total number of predictors to test a bagged model at the same time. I chose to have the random forest model calculate the importance of a feature based on its contribution to reducing impurity (Gini Index) since this is a common method that allows for easy interpretability. I selected the best metrics based on gain capture and ROC AUC because we want our model to predict customer categories accurately, and these metrics, respectively, maximize the number of true positive predictions and check our models ability to differentiate between groups.

Additionally, I tuned a decision tree using 10-fold cross validation. The resulting metrics were similar, but smaller than those achieved with the random forest model, especially in the gain capture. Therefore, for better predictive accuracy I recommend the random forest model while for clearer insights into what demographics are associated with these differences, if the variable importance plot from the random forest is not enough, and you do not mind a slight reduction model performance, you can use the decision tree model.

#### Part Five: Report to Sales

Now that your manager has approved your work, you're ready to present the results to Sales. The Sales team has zero data science training. They have some understanding of things like percentages, means, and medians - but they do not know or care about modeling details.

Summarize the results of your work in a way that is understandable to the Sales team, and only contains the level of technical detail that they might need to properly use the results in their job. You should NOT use any lingo. For example, instead of saying "We chose the model with highest precision", you should say, "We chose the model that was least likely to misclassify an A-type customer as B-type."

We chose a model with the goals of correctly classifying customers while allowing us to see what demographics influenced these classifications. The final model, on average, will correctly identify 59% of the customers of any given category, and will correctly differentiating between any two  customer categories 80% of the time. From the bar plot below, we can say that the customers tenure with the company, education group, and average salary are the most important demographics when categorizing a customer with this model, so we should focus our marketing strategies on these aspects. This is supported by the results of a second model, where exact cut off values for each variable are visible in the tree diagram provided. To read this tree, the letter in the box is the dominate customer category for the group, and splitting to the left is saying the expression below the box is true, while going to the right means that the expression is false. 

```{r}
importance(ranger_fit) %>%
  data.frame(Feature = names(.), Importance = .) %>%
  ggplot(aes(x = Importance, y = reorder(Feature, -Importance))) +
  geom_col(fill = 'firebrick') +
  theme_bw() +
  labs(
    x = 'Variable Importance',
    y = 'Features',
    title = 'Random Forest Variable Importance'
  )

rpart.plot(dc_tree_extracted$fit, roundint = FALSE)
```

