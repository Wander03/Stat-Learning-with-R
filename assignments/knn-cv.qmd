---
title: "Assignment 2: Cross-Validation and K-Nearest-Neighbors"
author: "Andrew Kerr"
format: 
  html:
    code-fold: false
    code-line-numbers: true
    code-tools: true
    embed-resources: true
editor: source
---

```{r}
#| label: packages
#| message: false
#| warning: false

set.seed(3849)

library(tidyverse)
library(tidymodels)
library(kableExtra)
```

# Instructions

Your document should also be clearly organized, so that it is easy for a reader to find your answers to each question. If I have a difficult time locating or reading your answer, you risk it being returned with a "revision requested".

# The Data

```{r}
#| label: load-data
#| message: false
whr_clean <- read_csv(here::here('data', 'whr_clean.csv'))

whr_clean <- whr_clean %>%
  mutate(
    regional_indicator = as_factor(regional_indicator)
  )

whr_clean %>% summary() %>% kable()
```

```{r}
#| label: cleaning NA

whr_clean %>%
  filter(if_any(everything(), is.na))

whr_clean <- whr_clean %>%
  mutate(
    regional_indicator = case_when(
      is.na(regional_indicator) ~ "Other",
      TRUE ~ regional_indicator
    ),
    log_gdp_per_capita = case_when(
      is.na(log_gdp_per_capita) ~ mean(log_gdp_per_capita, na.rm = TRUE),
      TRUE ~ log_gdp_per_capita
    ),
    healthy_life_expectancy = case_when(
      is.na(healthy_life_expectancy) ~ mean(healthy_life_expectancy, na.rm = TRUE),
      TRUE ~ healthy_life_expectancy
    ),
    social_support = case_when(
      is.na(social_support) ~ mean(social_support, na.rm = TRUE),
      TRUE ~ social_support
    ),
    freedom_to_make_life_choices = case_when(
      is.na(freedom_to_make_life_choices) ~ mean(freedom_to_make_life_choices, na.rm = TRUE),
      TRUE ~ freedom_to_make_life_choices
    ),
    generosity = case_when(
      is.na(generosity) ~ mean(generosity, na.rm = TRUE),
      TRUE ~ generosity
    ),
    perceptions_of_corruption = case_when(
      is.na(perceptions_of_corruption) ~ mean(perceptions_of_corruption, na.rm = TRUE),
      TRUE ~ perceptions_of_corruption
    ),
    regional_indicator = as_factor(regional_indicator)
  )
```

# Happiness Scores

## Part 1: Happiness Over Time

1.  Is the happiness in the world changing linearly over time? Fit a simple linear model and interpret the results to address this question.

```{r}
#| label: Q1

lin_reg <- linear_reg() %>%
  set_engine("lm") %>%
  set_mode("regression")

lr_m1 <- lin_reg %>%
  fit(happiness_score ~ year, data = whr_clean)

whr_clean <- whr_clean %>%
  mutate(
    prediction = predict(lr_m1, new_data = whr_clean)$.pred,
    residuals = happiness_score - prediction
    )

glance(lr_m1) %>% kable()
tidy(lr_m1) %>% kable()
```

The happiness in the world is not changing linearly over time since we see a low $R^2$ value of approx. 0, and a large p-value for the year coefficient.

2.  Was the happiness score approximately the same in all the years? Convert `year` to a factor variable, and fit a simple linear model to address this question.

```{r}
#| label: Q2

whr_clean <- whr_clean %>%
  mutate(year = as_factor(year))

lr_m2 <- lin_reg %>%
  fit(happiness_score ~ year, data = whr_clean)

tidy(lr_m2) %>% kable()
```

No, the happiness score was not approx. the same in all the years. We see highly significant p-values for all years compared to the baseline year of 2005, with 2005 being on average around 1 unit of happiness score greater than all the other years.

## Part 2: Happiness Equation

3.  How is each of the six measures of life quality weighted in calculating this score? Fit a model to estimate the weights, and interpret the coefficients.

```{r}
#| label: Q3

lr_recipe <- recipe(
  happiness_score ~ log_gdp_per_capita 
  + healthy_life_expectancy 
  + social_support 
  + freedom_to_make_life_choices 
  + generosity 
  + perceptions_of_corruption,
  data = whr_clean
  ) %>%
  step_normalize(all_numeric_predictors())

lr_wrkflw <- workflow() %>%
  add_recipe(lr_recipe) %>%
  add_model(lin_reg)

lr_wrkflw  %>%
  fit(whr_clean) %>%
  extract_fit_parsnip()
```

-   intercept: When all predictors are at there minimum values, the average happiness score is 5.46.
-   log_gdp_per_capita: If log GDP per capita moves from its lowest observed value to its highest, the average happiness score increases by 0.41 units, holding other predictors constant.
-   healthy_life_expectancy: Moving from the lowest observed life expectancy to the highest, the average happiness score increases by 0.23 units, holding other predictors constant.
-   social_support: Moving from the lowest observed social support to the highest, the average happiness score increases by 0.28 units, holding other predictors constant.
-   freedom_to_make_life_choices: If freedom to make life choices moves from its lowest observed value to its highest, the average happiness score increases by 0.16 units, holding other predictors constant.
-   generosity: If the generosity of society moves from its lowest observed value to its highest, the average happiness score increases by 0.11 units, holding other predictors constant.
-   perceptions_of_corruption: If perceptions of corruption in government moves from its lowest observed value to its highest, the average happiness score decreases by 0.09 units, holding other predictors constant.

4.  Which measures of life quality does the WHR consider to be most important to a country's happiness?

Log GDP per capita is the most important to a country's happiness since it has the larges coefficient, followed by social support and healthy life expectancy.

# Predicting Life Expectancy -- Exploring Linear Models

```{r}
#| label: pred-life-expectancy

whr_clean[, c(4, 6:9)] %>% cor()

whr_cvs <- vfold_cv(whr_clean, v = 10)

base_recipe <- recipe(
  healthy_life_expectancy ~ log_gdp_per_capita 
  + social_support 
  + freedom_to_make_life_choices 
  + generosity 
  + perceptions_of_corruption
  + regional_indicator,
  data = whr_clean
  ) %>%
  step_normalize(all_numeric_predictors())

life_wrkflw <- workflow() %>%
  add_recipe(base_recipe) %>%
  add_model(lin_reg)

life_wrkflw %>%
  fit_resamples(resamples = whr_cvs) %>%
  collect_metrics() %>% kable()
```

```{r}
#| label: full-model

full_recipe <- base_recipe %>%
  step_interact(terms = ~ log_gdp_per_capita:social_support +
                 log_gdp_per_capita:freedom_to_make_life_choices +
                 log_gdp_per_capita:generosity +
                 log_gdp_per_capita:perceptions_of_corruption +
                 log_gdp_per_capita:regional_indicator +
                 social_support:freedom_to_make_life_choices +
                 social_support:generosity +
                 social_support:perceptions_of_corruption +
                 social_support:regional_indicator +
                 freedom_to_make_life_choices:generosity +
                 freedom_to_make_life_choices:perceptions_of_corruption +
                 freedom_to_make_life_choices:regional_indicator +
                 generosity:perceptions_of_corruption +
                 generosity:regional_indicator +
                 perceptions_of_corruption:regional_indicator
               )

life_wrkflw <- workflow() %>%
  add_recipe(full_recipe) %>%
  add_model(lin_reg)

life_wrkflw %>%
  fit_resamples(resamples = whr_cvs) %>%
  collect_metrics() %>% kable()
```

```{r}
#| label: gdp-models

gdp_recipe <- recipe(
  healthy_life_expectancy ~ log_gdp_per_capita,
  data = whr_clean
  ) %>%
  step_normalize(all_numeric_predictors())

gdp_2_recipe <- gdp_recipe %>%
  step_poly(log_gdp_per_capita, degree = 2)

life_wrkflw <- workflow() %>%
  add_recipe(gdp_recipe) %>%
  add_model(lin_reg)

life_wrkflw %>%
  fit_resamples(resamples = whr_cvs) %>%
  collect_metrics() %>% kable()

life_wrkflw <- workflow() %>%
  add_recipe(gdp_2_recipe) %>%
  add_model(lin_reg)

life_wrkflw %>%
  fit_resamples(resamples = whr_cvs) %>%
  collect_metrics() %>% kable()
```

```{r}
#| label: social-models

social_recipe <- recipe(
  healthy_life_expectancy ~ social_support,
  data = whr_clean
  ) %>%
  step_normalize(all_numeric_predictors())

social_2_recipe <- social_recipe %>%
  step_poly(social_support, degree = 2)

life_wrkflw <- workflow() %>%
  add_recipe(social_recipe) %>%
  add_model(lin_reg)

life_wrkflw %>%
  fit_resamples(resamples = whr_cvs) %>%
  collect_metrics() %>% kable()

life_wrkflw <- workflow() %>%
  add_recipe(social_2_recipe) %>%
  add_model(lin_reg)

life_wrkflw %>%
  fit_resamples(resamples = whr_cvs) %>%
  collect_metrics() %>% kable()
```

```{r}
#| label: freedom-models

gdp_recipe <- recipe(
  healthy_life_expectancy ~ freedom_to_make_life_choices,
  data = whr_clean
  ) %>%
  step_normalize(all_numeric_predictors())

gdp_2_recipe <- gdp_recipe %>%
  step_poly(freedom_to_make_life_choices, degree = 2)

life_wrkflw <- workflow() %>%
  add_recipe(gdp_recipe) %>%
  add_model(lin_reg)

life_wrkflw %>%
  fit_resamples(resamples = whr_cvs) %>%
  collect_metrics() %>% kable()

life_wrkflw <- workflow() %>%
  add_recipe(gdp_2_recipe) %>%
  add_model(lin_reg)

life_wrkflw %>%
  fit_resamples(resamples = whr_cvs) %>%
  collect_metrics() %>% kable()
```

```{r}
#| label: generosity-models

gdp_recipe <- recipe(
  healthy_life_expectancy ~ generosity,
  data = whr_clean
  ) %>%
  step_normalize(all_numeric_predictors())

gdp_2_recipe <- gdp_recipe %>%
  step_poly(generosity, degree = 2)

life_wrkflw <- workflow() %>%
  add_recipe(gdp_recipe) %>%
  add_model(lin_reg)

life_wrkflw %>%
  fit_resamples(resamples = whr_cvs) %>%
  collect_metrics() %>% kable()

life_wrkflw <- workflow() %>%
  add_recipe(gdp_2_recipe) %>%
  add_model(lin_reg)

life_wrkflw %>%
  fit_resamples(resamples = whr_cvs) %>%
  collect_metrics()%>% kable()
```

```{r}
#| label: corruption-models

gdp_recipe <- recipe(
  healthy_life_expectancy ~ perceptions_of_corruption,
  data = whr_clean
  ) %>%
  step_normalize(all_numeric_predictors())

gdp_2_recipe <- gdp_recipe %>%
  step_poly(perceptions_of_corruption, degree = 2)

life_wrkflw <- workflow() %>%
  add_recipe(gdp_recipe) %>%
  add_model(lin_reg)

life_wrkflw %>%
  fit_resamples(resamples = whr_cvs) %>%
  collect_metrics() %>% kable()

life_wrkflw <- workflow() %>%
  add_recipe(gdp_2_recipe) %>%
  add_model(lin_reg)

life_wrkflw %>%
  fit_resamples(resamples = whr_cvs) %>%
  collect_metrics() %>% kable()
```

```{r}
#| label: region-models

gdp_recipe <- recipe(
  healthy_life_expectancy ~ regional_indicator,
  data = whr_clean
  )

life_wrkflw <- workflow() %>%
  add_recipe(gdp_recipe) %>%
  add_model(lin_reg)

life_wrkflw %>%
  fit_resamples(resamples = whr_cvs) %>%
  collect_metrics() %>% kable()
```

```{r}
#| label: reduced-model

reduced_recipe <- recipe(
  healthy_life_expectancy ~ log_gdp_per_capita 
  + freedom_to_make_life_choices 
  + generosity 
  + regional_indicator,
  data = whr_clean
  ) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(regional_indicator)

life_wrkflw <- workflow() %>%
  add_recipe(reduced_recipe) %>%
  add_model(lin_reg)

life_wrkflw %>%
  fit_resamples(resamples = whr_cvs) %>%
  collect_metrics() %>% kable()
```

```{r}
#| label: reduced-interaction-model

reduced_2_recipe <- reduced_recipe %>%
  step_interact(term = ~ log_gdp_per_capita:freedom_to_make_life_choices
                + freedom_to_make_life_choices:generosity)

life_wrkflw <- workflow() %>%
  add_recipe(reduced_2_recipe) %>%
  add_model(lin_reg)

life_wrkflw %>%
  fit_resamples(resamples = whr_cvs) %>%
  collect_metrics() %>% kable()
```

## Part 1: Summary of Approach

6.  Write a short description (bullet points are fine) of your process in narrowing down your model. How did you approach this problem, without spending hours upon hours fitting and cross-validating zillions of models?

- All models were fit using 10-Fold CV
- I created a main effects and full (all two-way interaction) model
- I created a model for each predictor, as well as their 2nd order poly term
- I looked a the correlation between each quantitative predictor
- GDP and social support have a correlation of .68 and freedom to make choices
and perceptions of corruption have a correlation of -.48. Thus, I removed the 
two predictors with smaller $R^2$ values in there single predictor models from 
my main effects model (-social support and -corruption)
- I tried adding the interactions of somewhat correlated values to my reduced 
model to see if they would improve the model.

## Part 2: Three Candidates

8.  Choose the three best candidate models among those you tried.

- full model
- reduced model
- reduced interaction model

9.  Supply your code and results for comparing these models, and discuss how you decided which *one* model was the best one.

```{r}
#| label: Q9

full_recipe <- base_recipe %>%
  step_interact(terms = ~ log_gdp_per_capita:social_support +
                 log_gdp_per_capita:freedom_to_make_life_choices +
                 log_gdp_per_capita:generosity +
                 log_gdp_per_capita:perceptions_of_corruption +
                 log_gdp_per_capita:regional_indicator +
                 social_support:freedom_to_make_life_choices +
                 social_support:generosity +
                 social_support:perceptions_of_corruption +
                 social_support:regional_indicator +
                 freedom_to_make_life_choices:generosity +
                 freedom_to_make_life_choices:perceptions_of_corruption +
                 freedom_to_make_life_choices:regional_indicator +
                 generosity:perceptions_of_corruption +
                 generosity:regional_indicator +
                 perceptions_of_corruption:regional_indicator
               )

reduced_recipe <- recipe(
  healthy_life_expectancy ~ log_gdp_per_capita 
  + freedom_to_make_life_choices 
  + generosity 
  + regional_indicator,
  data = whr_clean
  ) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(regional_indicator)

reduced_2_recipe <- reduced_recipe %>%
  step_interact(term = ~ log_gdp_per_capita:freedom_to_make_life_choices
                + freedom_to_make_life_choices:generosity)


full_wrkflw <- workflow() %>%
  add_recipe(full_recipe) %>%
  add_model(lin_reg)

reduced_wrkflw <- workflow() %>%
  add_recipe(reduced_recipe) %>%
  add_model(lin_reg)

redcued_interaction_wrkflw <- workflow() %>%
  add_recipe(reduced_2_recipe) %>%
  add_model(lin_reg)


full_tbl <- full_wrkflw %>%
  fit_resamples(resamples = whr_cvs) %>%
  collect_metrics()

reduced_tbl <- reduced_wrkflw %>%
  fit_resamples(resamples = whr_cvs) %>%
  collect_metrics()

reduced_interaction_tbl <- redcued_interaction_wrkflw %>%
  fit_resamples(resamples = whr_cvs) %>%
  collect_metrics()

bind_rows(
  full_tbl %>% mutate(model = "Full Model"),
  reduced_tbl %>% mutate(model = "Reduced Model"),
  reduced_interaction_tbl %>% mutate(model = "Reduced Interaction Model")
) %>% kable()
```

I decided that the reduced model was the best model. Although the reduced with
interactions as a slightly higher $R^2$ value, it is by less than .01 with a 
small reduction in RMSE. I did not select the full model even though it has a 
much smaller RMSE and a larger $R^2$ value because it has strongly correlated 
predictors.

## Part 3: Final Model

10. Summarize the results from your final model. Don't forget to fit your final model on the **full** dataset, even if you used *test / training* data or *cross-validation* during the model selection process.

```{r}
#| label: Q10

fit_model <- reduced_wrkflw %>%
  fit(whr_clean) %>%
  extract_fit_parsnip() 

fit_model %>%
  tidy() %>%
  kable()

fit_model %>%
  glance() %>% 
  kable()
```

GDP is the most important predictor outside of certain regional levels. This 
model has an $R^2$ value of 0.81, meaning that it accounts for 81% of the
variability in healthy life expectancy.

11. Include a plot of the residuals and discussion of what you see, and interpretations of the coefficients and metrics.

```{r}
#| label: Q11

whr_clean <- whr_clean %>%
  mutate(
    prediction = predict(reduced_wrkflw %>% fit(whr_clean), new_data = whr_clean)$.pred,
    residuals = healthy_life_expectancy - prediction
    )

whr_clean %>%
  ggplot(aes(x = prediction, y = residuals)) +
    geom_point() +
  labs(x = 'fitted') +
    theme_bw()
```

The residual plot looks fairly random, which is good!

- intercept: When all predictors are at there minimum values, the average life expectancy is 63 years.
- log_gdp_per_capita: If log GDP per capita moves from its lowest observed value to its highest, the average life expectancy increases by 3.29 years, holding other predictors constant.
- freedom_to_make_life_choices: If freedom to make life choices moves from its lowest observed value to its highest, the average life expectancy increases by 0.78 years, holding other predictors constant
- generosity: If generosity moves from its lowest observed value to its highest, the average life expectancy decreases by 0.37 years, holding other predictors constant
- regional_indicator: People living in [Central and Eastern Europe] have an average life expectancy [2.22] years [more] than people in South Asia. 
  - replace region in brackets and coefficient in brackets to get interpretation for each region (change more to less if negative coefficient)

# Predicting Life Expectancy -- K-Nearest-Neighbors

## Part 1: Tuning K

12. For **each** of your top three candidate models from Q8, find the best choice of **K**. Show all your work, and provide a brief summary at the end (e.g., "For Model 1, we choose a K of \[something\] because \[reasons\]. For Model 2, ...")

```{r}
#| label: Q12

# k_grid <- grid_regular(neighbors(c(1,50)), 
#                        levels = 25)

k_grid <- grid_regular(neighbors(c(6,11)),
                       levels = 6)

knn_mod_tune <- nearest_neighbor(neighbors = tune()) %>%
  set_engine("kknn") %>%
  set_mode("regression")

full_wflow <- workflow() %>%
  add_recipe(full_recipe) %>%
  add_model(knn_mod_tune)

reduced_wflow <- workflow() %>%
  add_recipe(reduced_recipe) %>%
  add_model(knn_mod_tune)

reduced_2_wflow <- workflow() %>%
  add_recipe(reduced_2_recipe) %>%
  add_model(knn_mod_tune)

whr_cv <- vfold_cv(whr_clean, v = 10)

################################################################################

knn_grid_search_full <-
  tune_grid(
    full_wflow,
    resamples = whr_cv,
    grid = k_grid
  )

knn_grid_search_reduced <-
  tune_grid(
    reduced_wflow,
    resamples = whr_cv,
    grid = k_grid
  )

knn_grid_search_reduced_2 <-
  tune_grid(
    reduced_2_wflow,
    resamples = whr_cv,
    grid = k_grid
  )

################################################################################

full_tbl <- knn_grid_search_full %>% 
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  slice_min(mean, n = 3)

reduced_tbl <- knn_grid_search_reduced %>% 
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  slice_min(mean, n = 3)

reduced_interaction_tbl <- knn_grid_search_reduced_2 %>% 
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  slice_min(mean, n = 3)

bind_rows(
  full_tbl %>% mutate(model = "Full Model"),
  reduced_tbl %>% mutate(model = "Reduced Model"),
  reduced_interaction_tbl %>% mutate(model = "Reduced Interaction Model")
) %>% kable()
```

I first ran all three models on a grid search between k = 1 and k = 50 with 25 
levels. Looking at the values of k with the lowest RMSE, all models had k = 7
and k = 9 in the top 2, so I ran all three models on a grid search between k = 6
and k = 11 with 6 levels. Now, the best value of k for the full model is 8, the 
reduced model is 8, and the reduced model with interaction is 6 (although the 
top 3 k's based on minimum RMSE are very close).

## Part 2: Best Model

13. Fit and report your single best model from Q9.

You should include:

-   An argument for your choice of K, including a plot.

-   A plot of the residuals

```{r}
#| label: Q13

k_grid <- grid_regular(neighbors(c(1,15)),
                       levels = 15)

whr_cv <- vfold_cv(whr_clean, v = 10)

knn_mod_tune <- nearest_neighbor(neighbors = tune()) %>%
  set_engine("kknn") %>%
  set_mode("regression")

full_wflow <- workflow() %>%
  add_recipe(full_recipe) %>%
  add_model(knn_mod_tune)

knn_grid_search_full <-
  tune_grid(
    full_wflow,
    resamples = whr_cv,
    grid = k_grid
  )

min_k_rmse <- knn_grid_search_full %>% 
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  slice_min(mean, n = 1) %>%
  pull(neighbors)

min_k_rsq <- knn_grid_search_full %>% 
  collect_metrics() %>%
  filter(.metric == "rsq") %>%
  slice_max(mean, n = 1) %>%
  pull(neighbors)

knn_grid_search_full %>% 
  collect_metrics() %>%
  ggplot(aes(x = neighbors, y = mean, color = .metric)) +
    geom_line() +
    geom_vline(xintercept = min_k_rmse, color = 'firebrick') +
    geom_vline(xintercept = min_k_rsq, color = 'cornflowerblue', linetype = 'dashed') +
    theme_bw()

################################################################################

knn_model <- nearest_neighbor(neighbors = 8) %>%
  set_mode("regression") %>% 
  set_engine("kknn")

full_wflow <- workflow() %>%
  add_recipe(full_recipe) %>%
  add_model(knn_model)

knn_fit <- full_wflow %>% fit(whr_clean) 
knn_pred <- knn_fit %>% predict(whr_clean)
knn_resid <- whr_clean$healthy_life_expectancy - knn_pred$.pred

ggplot() +
  geom_point(aes(x = knn_pred$.pred, y = knn_resid)) +
  geom_hline(yintercept = 0, linetype = 'dashed', color = 'firebrick') +
  labs(
    x = 'Fitted Values',
    y = 'Residuals',
    title = 'Fitted v. Residuals'
  ) +
  theme_bw()
```

The best model based on smallest RMSE is the full model with k = 8. As seen in
the first plot, the red line for RMSE decreases until kk = 7, then begins 
increasing at k = 9. Meanwhile the blue line for $R^2$ increases then stays 
constant after k = 5. Zooming in, we can see that the minimum value for RMSE and 
the maximum value for $R^2$ is at k = 8, as denoted by the overlapping solid and 
dashed lines. The residuals plot shows a slight fanning shape, with higher
variance at lower values and smaller variance at higher values.

# Predicting on New Data

14. Use your **one** best *least-squares regression* model (Q9) to predict the life expectancy of all countries.

```{r}
#| label: Q14
#| message: false

whr_new <- read_csv(here::here('data', 'whr_2020.csv'))

reduced_wrkflw <- workflow() %>%
  add_recipe(reduced_recipe) %>%
  add_model(lin_reg)

lm_predicted <- reduced_wrkflw %>%
  fit(whr_clean) %>%
  predict(new_data = whr_new)
```

15. Use your **one** best *KNN* model (Q13) to predict the life expectancy of all countries.

```{r}
#| label: Q15

full_wrkflw <- workflow() %>%
  add_recipe(full_recipe) %>%
  add_model(knn_model)

knn_predicted <- full_wrkflw %>%
  fit(whr_clean) %>%
  predict(new_data = whr_new)
```

16. Which model did a better job predicting the true values in the new data?

```{r}
whr_new %>%
  mutate(
    residuals_lm = healthy_life_expectancy - lm_predicted$.pred,
    residuals_knn = healthy_life_expectancy - knn_predicted$.pred
  ) %>%
  summarise(
    lm_mse = mean(residuals_lm^2),
    knn_mse = mean(residuals_knn^2)
  )
```

The KNN model did a better job predicting the true values in the new data as
evident in its smaller MSE value.

# Discussion Questions

## Parametric and Non-Parametric

17. Make an argument for why a **parametric** method, like least-squares regression, might be preferred in this task.

A parametric method might be preferred in this task if your goal is 
interpretability. This method returns coefficients, which, for example,  can tell you what 
predictors are most influential in predicting the response. Additionally, if the relationship
between predictors and response is linear, then this model would perform better.

18. Then make an argument for why a **non-parametric** method, like K-Nearest-Neighbors, might be preferred.

A non-parametric method might be preferred if your goal is prediction. This method
does not help with interpreting since it only returns predictions, but can work with
a wider variety of relationships between predictors and response. 

## Interpretation and Prediction

19. If your only goal were **interpretation**, which of the candidate models (from *any* section of the assignment) would you have chosen? Why?

I would have chosen my reduced model from my linear models. To start, linear models
are better than KNN models for interpretation because they provide coefficients to interpret. I would select
my reduced model over those with interactions because interactions are difficult to interpret, and in this situation did
not improve the model enough to be worthwhile in keeping (only +0.01 in $R^2$).

20. If your only goal were **prediction** on future data, which of the candidate models would you have chosen? Why?

If my only goal was prediction then I would have chosen my best KNN model (full model). This is because the residuals tell
us the shape of the data is not linear, so I do not want a linear model but a non-parametric model like KNN. I would select the 
full model because it resulted in the lowest RMSE value.

## Standardization

21. Consider your final best least-squares regression model from Q9. Suppose we fit this model again, but this time, we normalize **all** of the quantitative variables. Will anything change? Give a (conceptual) argument for why this is true.

Well seeing how I DID normalize already, I will pretend I did not here :). Normalizing all
of the quantitative variables would put them on the same scale, allowing us to compare them to each other. This would change the size of
the coefficients, but would not change the predicted values or relationships between the response and predictors. This makes sense because 
normalizing the variables is a linear transformation, and any changes to the predictors this way are taken care of as changes to the coefficents, leaving the predictions the same.

## Quantitative or Categorical?

22. Suppose we add the predictor `year` to our final model as a **categorical variable** and fit the model on all the data. Then, we use this new model to predict on the 2020 data. What is wrong with this plan?

The problem is that we are now predicting on data our model has not seen, Treating year as
a categorical variable makes each year a level, and 2020 is not a level our model has been trained on. Thus, it has
not coefficient for this level and can not predict on it.

